force_backward: true
name: "SubpxconvGenerator"
layer {
  name: "noise"
  type: "RandVec"
  top: "noise"
  randvec_param {
    batch_size: 256
    dim: 128
    lower: -1.0
    upper: 1.0
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "noise"
  top: "fc1"
  inner_product_param {
    num_output: 8192
    weight_filler {
      type: "msra"
      
    }
  }
}
layer {
  name: "reshape"
  type: "Reshape"
  bottom: "fc1"
  top: "reshape_fc1"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 4
      dim: 4
    }
  }
}
layer {
  name: "fc1_BN"
  type: "BatchNorm" include {phase: TRAIN}
  bottom: "reshape_fc1"
  top: "fc1_BN"
  param {  
    lr_mult: 0  
    decay_mult: 0  
  }   
  param {  
    lr_mult: 0  
    decay_mult: 0  
  }  
  param {  
    lr_mult: 0  
    decay_mult: 0  
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
  }
}
layer {
  name: "fc1_BN"
  type: "BatchNorm" include {phase: TEST}
  bottom: "reshape_fc1"
  top: "fc1_BN"
  param {  
    lr_mult: 0  
    decay_mult: 0  
  }   
  param {  
    lr_mult: 0  
    decay_mult: 0  
  }  
  param {  
    lr_mult: 0  
    decay_mult: 0  
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
  }
}
layer {
    name: "scale_fc1"
    type: "Scale"
    bottom: "fc1_BN"
    top: "scale_fc1"
    param {
        lr_mult: 1
        decay_mult: 1
    }
    param {
        lr_mult: 1
        decay_mult: 1
    }
    scale_param {
      bias_term: true
    }
}
layer {
  name: "relu_fc1"
  type: "ReLU"
  bottom: "scale_fc1"
  top: "relu_fc1"
}
layer {
  name: "conv1"           
  type: "Convolution"
  bottom: "relu_fc1"
  top: "conv1"
  convolution_param {
    num_output: 1024#256 
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
      
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pxs1"           
  type: "Reshape"
  bottom: "conv1"
  top: "pxs1"
  reshape_param {
    pixelshuffler: 2
  }
} # 8x8
layer {
  name: "conv1_BN"
  type: "BatchNorm" include { phase: TRAIN}
  bottom: "pxs1"
  top: "conv1_BN"
  param {
    lr_mult: 0  
    decay_mult: 0  
  }   
  param {  
    lr_mult: 0  
    decay_mult: 0  
  }  
  param {  
    lr_mult: 0  
    decay_mult: 0  
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
  }
}
layer {
  name: "conv1_BN"
  type: "BatchNorm" include { phase: TEST}
  bottom: "pxs1"
  top: "conv1_BN"
  param {
    lr_mult: 0  
    decay_mult: 0  
  }   
  param {  
    lr_mult: 0  
    decay_mult: 0  
  }  
  param {  
    lr_mult: 0  
    decay_mult: 0  
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
  }
}
layer {
    name: "scale1"
    type: "Scale"
    bottom: "conv1_BN"
    top: "scale1"
    param {
        lr_mult: 1
        decay_mult: 1
    }
    param {
        lr_mult: 1
        decay_mult: 1
    }
    scale_param {
      bias_term: true
    }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "scale1"
  top: "relu_conv1"
}
layer {
  name: "conv2"           
  type: "Convolution"
  bottom: "relu_conv1"
  top: "conv2"
  convolution_param {
    num_output: 512#128 
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
      
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pxs_2"           
  type: "Reshape"
  bottom: "conv2"
  top: "pxs_2"
  reshape_param {
    pixelshuffler: 2
  }
}
layer {
  name: "conv2_BN"
  type: "BatchNorm" include { phase: TRAIN}
  bottom: "pxs_2"
  top: "conv2_BN"
  param {
    lr_mult: 0  
    decay_mult: 0  
  }   
  param {  
    lr_mult: 0  
    decay_mult: 0  
  }  
  param {  
    lr_mult: 0  
    decay_mult: 0  
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
  }
}
layer {
  name: "conv2_BN"
  type: "BatchNorm" include { phase: TEST}
  bottom: "pxs_2"
  top: "conv2_BN"
  param {
    lr_mult: 0  
    decay_mult: 0  
  }   
  param {  
    lr_mult: 0  
    decay_mult: 0  
  }  
  param {  
    lr_mult: 0  
    decay_mult: 0  
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
  }
}
layer {
    name: "scale2"
    type: "Scale"
    bottom: "conv2_BN"
    top: "scale2"
    param {
        lr_mult: 1
        decay_mult: 1
    }
    param {
        lr_mult: 1
        decay_mult: 1
    }
    scale_param {
      bias_term: true
    }
}
layer {
  name: "relu_conv2"
  type: "ReLU"
  bottom: "scale2"
  top: "relu_conv2"
}
layer {
  name: "conv3"           
  type: "Convolution"
  bottom: "relu_conv2"
  top: "conv3"
  convolution_param {
    num_output: 256#64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
      
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pxs3"           
  type: "Reshape"
  bottom: "conv3"
  top: "pxs3"
  reshape_param {
    pixelshuffler: 2
  }
}
layer {
  name: "conv3_BN"
  type: "BatchNorm" include { phase: TRAIN}
  bottom: "pxs3"
  top: "conv3_BN"
  param {
    lr_mult: 0  
    decay_mult: 0  
  }   
  param {  
    lr_mult: 0  
    decay_mult: 0  
  }  
  param {  
    lr_mult: 0  
    decay_mult: 0  
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
  }
}
layer {
  name: "conv3_BN"
  type: "BatchNorm" include { phase: TEST}
  bottom: "pxs3"
  top: "conv3_BN"
  param {
    lr_mult: 0  
    decay_mult: 0  
  }   
  param {  
    lr_mult: 0  
    decay_mult: 0  
  }  
  param {  
    lr_mult: 0  
    decay_mult: 0  
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.9
  }
}
layer {
    name: "scale3"
    type: "Scale"
    bottom: "conv3_BN"
    top: "scale3"
    param {
        lr_mult: 1
        decay_mult: 1
    }
    param {
        lr_mult: 1
        decay_mult: 1
    }
    scale_param {
      bias_term: true
    }
}
layer {
  name: "relu_conv3"
  type: "ReLU"
  bottom: "scale3"
  top: "relu_conv3"
}
layer {
  name: "conv_out"           
  type: "Convolution"
  bottom: "relu_conv3"
  top: "conv_out"
  convolution_param {
    num_output: 3
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
      
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output"
  type: "TanH"
  bottom: "conv_out"
  top: "output"
}